{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三章：PyTorch的主要组成模块\n",
    "### 3.1 思考：完成深度学习的必要部分\n",
    "\n",
    "回顾我们在完成一项机器学习任务时的步骤，首先需要对数据进行预处理，其中重要的步骤包括数据格式的统一和必要的数据变换，同时划分训练集和测试集。接下来选择模型，并设定损失函数和优化函数，以及对应的超参数（当然可以使用sklearn这样的机器学习库中模型自带的损失函数和优化器）。最后用模型去拟合训练集数据，并在验证集/测试集上计算模型表现。\n",
    "\n",
    "深度学习和机器学习在流程上类似，但在代码实现上有较大的差异。首先，由于深度学习所需的样本量很大，一次加载全部数据运行可能会超出内存容量而无法实现；同时还有批（batch）训练等提高模型表现的策略，需要每次训练读取固定数量的样本送入模型中训练，因此深度学习在数据加载上需要有专门的设计。\n",
    "\n",
    "在模型实现上，深度学习和机器学习也有很大差异。由于深度神经网络层数往往较多，同时会有一些用于实现特定功能的层（如卷积层、池化层、批正则化层、LSTM层等），因此深度神经网络往往需要“逐层”搭建，或者预先定义好可以实现特定功能的模块，再把这些模块组装起来。这种“定制化”的模型构建方式能够充分保证模型的灵活性，也对代码实现提出了新的要求。\n",
    "\n",
    "接下来是损失函数和优化器的设定。这部分和经典机器学习的实现是类似的。但由于模型设定的灵活性，因此损失函数和优化器要能够保证反向传播能够在用户自行定义的模型结构上实现。\n",
    "\n",
    "上述步骤完成后就可以开始训练了。我们前面介绍了GPU的概念和GPU用于并行计算加速的功能，不过程序默认是在CPU上运行的，因此在代码实现中，需要把模型和数据“放到”GPU上去做运算，同时还需要保证损失函数和优化器能够在GPU上工作。如果使用多张GPU进行训练，还需要考虑模型和数据分配、整合的问题。此外，后续计算一些指标还需要把数据“放回”CPU。这里涉及到了一系列有关于GPU的配置和操作。\n",
    "\n",
    "深度学习中训练和验证过程最大的特点在于读入数据是按批的，每次读入一个批次的数据，放入GPU中训练，然后将损失函数反向传播回网络最前面的层，同时使用优化器调整网络参数。这里会涉及到各个模块配合的问题。训练/验证后还需要根据设定好的指标计算模型表现。\n",
    "\n",
    "经过以上步骤，一个深度学习任务就完成了。我们在详细讲解每个部分之前，先梳理了完成各个部分所需的功能，下面我们就去进一步了解一下PyTorch是如何实现各个部分的，以及PyTorch作为一个深度学习框架拥有的模块化特点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 基本配置\n",
    "首先导入必须的包。对于一个PyTorch项目，我们需要导入一些Python常用的包来帮助我们快速实现功能。常见的包有os、numpy等，此外还需要调用PyTorch自身一些模块便于灵活使用，比如torch、torch.nn、torch.utils.data.Dataset、torch.utils.data.DataLoader、torch.optimizer等等。注意这里**只是建议导入的包导入的方式**，可以采用不同的方案，比如涉及到表格信息的读入很可能用到pandas，对于不同的项目可能还需要导入一些更上层的包如cv2等。如果涉及可视化还会用到matplotlib、seaborn等。涉及到下游分析和指标计算也常用到sklearn。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据前面我们对深度学习任务的梳理，有如下几个超参数可以统一设置，方便后续调试时修改：\n",
    "\n",
    "- batch size\n",
    "\n",
    "- 初始学习率（初始）\n",
    "\n",
    "- 训练次数（max_epochs）\n",
    "\n",
    "- GPU配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "max_epochs = 100\n",
    "\n",
    "# GPU的设置有两种常见的方式：\n",
    "# 方案一：使用os.environ，这种情况如果使用GPU不需要设置\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 当然还会有一些其他模块或用户自定义模块会用到的参数，有需要也可以在一开始进行设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 数据读入\n",
    "PyTorch数据读入是通过Dataset+DataLoader的方式完成的，Dataset定义好数据的格式和数据变换形式，DataLoader用iterative的方式不断读入批次数据。\n",
    "\n",
    "我们可以定义自己的Dataset类来实现灵活的数据读取，定义的类需要继承PyTorch自身的Dataset类。主要包含三个函数：\n",
    "\n",
    "- `__init__`: 用于向类中传入外部参数，同时定义样本集\n",
    "- `__getitem__`: 用于逐个读取样本集合中的元素，可以进行一定的变换，并将返回训练/验证所需的数据\n",
    "- `__len__`: 用于返回数据集的样本数\n",
    "\n",
    "下面以cifar10数据集为例给出构建Dataset类的方式：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# train_data = torchvision.datasets.ImageFolder(train_path, transform=data_transform)\n",
    "# val_data = torchvision.datasets.ImageFolder(val_path, transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里使用了PyTorch自带的ImageFolder类的用于读取按一定结构存储的图片数据（path对应图片存放的目录，目录下包含若干子目录，每个子目录对应属于同一个类的图片）。\n",
    "\n",
    "其中“data_transform”可以对图像进行一定的变换，如翻转、裁剪等操作，可自己定义。这里我们会在下一章通过实战加以介绍。\n",
    "\n",
    "这里另外给出一个例子，其中图片存放在一个文件夹，另外有一个csv文件给出了图片名称对应的标签。这种情况下需要自己来定义Dataset类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, info_csv, image_list, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            info_csv: path to the csv file containing image indexes\n",
    "                with corresponding labels.\n",
    "            image_list: path to the txt file contains image names to training/validation set\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        label_info = pd.read_csv(info_csv)\n",
    "        image_file = open(image_list).readlines()\n",
    "        self.data_dir = data_dir\n",
    "        self.image_file = image_file\n",
    "        self.label_info = label_info\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_file[index].strip('\\n')\n",
    "        raw_label = self.label_info.loc[self.label_info['Image_index'] == image_name]\n",
    "        label = raw_label.iloc[:,0]\n",
    "        image_name = os.path.join(self.data_dir, image_name)\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好Dataset后，就可以使用DataLoader来按批次读入数据了，实现代码如下：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中:\n",
    "\n",
    "- batch_size：样本是按“批”读入的，batch_size就是每次读入的样本数\n",
    "\n",
    "- num_workers：有多少个进程用于读取数据\n",
    "\n",
    "- shuffle：是否将读入的数据打乱\n",
    "\n",
    "- drop_last：对于样本最后一部分没有达到批次数的样本，使其不再参与训练\n",
    "\n",
    "这里可以看一下我们的加载的数据。PyTorch中的DataLoader的读取可以使用next和iter来完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images, labels = next(iter(val_loader))\n",
    "print(images.shape)\n",
    "plt.imshow(images[0].transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 模型构建\n",
    "#### 3.4.1 神经网络的构造\n",
    "PyTorch中神经网络构造一般是基于 Module 类的模型来完成的，它让模型构造更加灵活。\n",
    "\n",
    "Module 类是 nn 模块里提供的一个模型构造类，是所有神经⽹网络模块的基类，我们可以继承它来定义我们想要的模型。下面继承 Module 类构造多层感知机。这里定义的 MLP 类重载了 Module 类的 init 函数和 forward 函数。它们分别用于创建模型参数和定义前向计算。前向计算也即正向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "  def __init__(self, **kwargs):\n",
    "    # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "    super(MLP, self).__init__(**kwargs)\n",
    "    self.hidden = nn.Linear(784, 256)\n",
    "    self.act = nn.ReLU()\n",
    "    self.output = nn.Linear(256,10)\n",
    "    \n",
    "   # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "  def forward(self, x):\n",
    "    o = self.act(self.hidden(x))\n",
    "    return self.output(o)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上的 MLP 类中⽆须定义反向传播函数。系统将通过⾃动求梯度⽽自动⽣成反向传播所需的 backward 函数。\n",
    "\n",
    "我们可以实例化 MLP 类得到模型变量 net 。下⾯的代码初始化 net 并传入输⼊数据 X 做一次前向计算。其中， net(X) 会调用 MLP 继承⾃自 Module 类的 call 函数，这个函数将调⽤用 MLP 类定义的forward 函数来完成前向计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1020,  0.0023,  0.0523,  0.0668, -0.0928,  0.0823, -0.2623, -0.1813,\n",
       "         -0.0592,  0.0635],\n",
       "        [ 0.0008, -0.0313, -0.0199,  0.0857, -0.1672,  0.0545, -0.2838, -0.1612,\n",
       "         -0.1343, -0.0011]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2,784)\n",
    "net = MLP()\n",
    "print(net)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这里并没有将 Module 类命名为 Layer (层)或者 Model (模型)之类的名字，这是因为该类是一个可供⾃由组建的部件。它的子类既可以是⼀个层(如PyTorch提供的 Linear 类)，⼜可以是一个模型(如这里定义的 MLP 类)，或者是模型的⼀个部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 神经网络中常见的层\n",
    "深度学习的一个魅力在于神经网络中各式各样的层，例如全连接层、卷积层、池化层与循环层等等。虽然PyTorch提供了⼤量常用的层，但有时候我们依然希望⾃定义层。这里我们会介绍如何使用 Module 来自定义层，从而可以被反复调用。\n",
    "\n",
    "- **不含模型参数的层**\n",
    "\n",
    "我们先介绍如何定义一个不含模型参数的自定义层。下⾯构造的 MyLayer 类通过继承 Module 类自定义了一个**将输入减掉均值后输出**的层，并将层的计算定义在了 forward 函数里。这个层里不含模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLayer, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x - x.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试，实例化该层，然后做前向计算\n",
    "layer = MyLayer()\n",
    "layer(torch.tensor([1, 2, 3, 4, 5], dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **含模型参数的层**\n",
    "\n",
    "我们还可以自定义含模型参数的自定义层。其中的模型参数可以通过训练学出。\n",
    "\n",
    "Parameter 类其实是 Tensor 的子类，如果一 个 Tensor 是 Parameter ，那么它会⾃动被添加到模型的参数列表里。所以在⾃定义含模型参数的层时，我们应该将参数定义成 Parameter ，除了直接定义成 Parameter 类外，还可以使⽤ ParameterList 和 ParameterDict 分别定义参数的列表和字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyListDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "net = MyListDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))}) # 新增\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)\n",
    "\n",
    "# 下面给出常见的神经网络的一些层，比如卷积层、池化层，以及较为基础的AlexNet，LeNet等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **二维卷积层**\n",
    "\n",
    "二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 卷积运算（二维互相关）\n",
    "def corr2d(X, K): \n",
    "    h, w = K.shape\n",
    "    X, K = X.float(), K.float()\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "# 二维卷积层\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积窗口形状为 \\(p \\times q\\) 的卷积层称为 \\(p \\times q\\) 卷积层。同样， \\(p \\times q\\) 卷积或 \\(p \\times q\\) 卷积核说明卷积核的高和宽分别为 \\(p\\) 和 \\(q\\)。\n",
    "\n",
    "填充(padding)是指在输⼊高和宽的两侧填充元素(通常是0元素)。\n",
    "\n",
    "下面的例子里我们创建一个⾼和宽为3的二维卷积层，然后设输⼊高和宽两侧的填充数分别为1。给定一 个高和宽为8的输入，我们发现输出的高和宽也是8。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:]) # 排除不关心的前两维:批量和通道\n",
    "\n",
    "\n",
    "# 注意这里是两侧分别填充1⾏或列，所以在两侧一共填充2⾏或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3,padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当卷积核的高和宽不同时，我们也可以通过设置高和宽上不同的填充数使输出和输入具有相同的高和宽。\n",
    "\n",
    "# 使用高为5、宽为3的卷积核。在⾼和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "# 在二维互相关运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下 的顺序，\n",
    "# 依次在输⼊数组上滑动。我们将每次滑动的行数和列数称为步幅(stride)。\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **池化层**\n",
    "\n",
    "池化层每次对输入数据的一个固定形状窗口(⼜称池化窗口)中的元素计算输出。不同于卷积层里计算输⼊和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也 分别叫做最大池化或平均池化。在二维最⼤池化中，池化窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输⼊数组上滑动。当池化窗口滑动到某⼀位置时，窗口中的输入子数组的最大值即输出数组中相应位置的元素。\n",
    "\n",
    "下面把池化层的前向计算实现在`pool2d`函数里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]], dtype=torch.float)\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用`torch.nn`包来构建神经网络。我们已经介绍了`autograd`包，`nn`包则依赖于`autograd`包来定义模型并对它们求导。一个`nn.Module`包含各个层和一个`forward(input)`方法，该方法返回`output`。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 模型示例\n",
    "\n",
    "#####  **LeNet**\n",
    "\n",
    "![3.4.1](https://datawhalechina.github.io/thorough-pytorch/_images/3.4.1.png)\n",
    "\n",
    "这是一个简单的前馈神经网络 (feed-forward network）（LeNet）。它接受一个输入，然后将它送入下一层，一层接一层的传递，最后给出输出。\n",
    "\n",
    "一个神经网络的典型训练过程如下：\n",
    "\n",
    "1. 定义包含一些可学习参数(或者叫权重）的神经网络\n",
    "2. 在输入数据集上迭代\n",
    "3. 通过网络处理输入\n",
    "4. 计算 loss (输出和正确答案的距离）\n",
    "5. 将梯度反向传播给网络的参数\n",
    "6. 更新网络的权重，一般使用一个简单的规则：`weight = weight - learning_rate * gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2x2 Max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 如果是方阵,则可以只使用一个数字进行定义\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # 除去批处理维度的其他所有维度\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们只需要定义 `forward` 函数，`backward`函数会在使用`autograd`时自动定义，`backward`函数用来计算导数。我们可以在 `forward` 函数中使用任何针对张量的操作和计算。\n",
    "\n",
    "一个模型的可学习参数可以通过`net.parameters()`返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们尝试一个随机的 32x32 的输入。注意:这个网络 (LeNet）的期待输入是 32x32 的张量。如果使用 MNIST 数据集来训练这个网络，要把图片大小重新调整到 32x32。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2296,  0.0041,  0.0776, -0.1270,  0.0846, -0.0464, -0.1176, -0.0244,\n",
      "          0.1141,  0.1952]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清零所有参数的梯度缓存，然后进行随机梯度的反向传播：\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：`torch.nn`只支持小批量处理 (mini-batches）。整个 `torch.nn` 包只支持小批量样本的输入，不支持单个样本的输入。比如，`nn.Conv2d` 接受一个4维的张量，即`nSamples x nChannels x Height x Width `如果是一个单独的样本，只需要使用`input.unsqueeze(0)` 来添加一个“假的”批大小维度。\n",
    "\n",
    "- `torch.Tensor` - 一个多维数组，支持诸如`backward()`等的自动求导操作，同时也保存了张量的梯度。\n",
    "- `nn.Module `- 神经网络模块。是一种方便封装参数的方式，具有将参数移动到GPU、导出、加载等功能。\n",
    "- `nn.Parameter `- 张量的一种，当它作为一个属性分配给一个`Module`时，它会被自动注册为一个参数。\n",
    "- `autograd.Function` - 实现了自动求导前向和反向传播的定义，每个`Tensor`至少创建一个`Function`节点，该节点连接到创建`Tensor`的函数并对其历史进行编码。\n",
    "\n",
    "下面再介绍一个比较基础的案例AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **AlexNet**\n",
    "\n",
    "![3.4.2](https://datawhalechina.github.io/thorough-pytorch/_images/3.4.2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 模型初始化\n",
    "\n",
    "在深度学习模型的训练中，权重的初始值极为重要。一个好的权重值，会使模型收敛速度提高，使模型准确率更精确。为了利于训练和减少收敛时间，我们需要对模型进行合理的初始化。PyTorch也在`torch.nn.init`中为我们提供了常用的初始化方法。 通过本章学习，你将学习到以下内容：\n",
    "\n",
    "- 常见的初始化函数\n",
    "- 初始化函数的使用\n",
    "\n",
    "#### torch.nn.init内容\n",
    "\n",
    "通过访问torch.nn.init的官方文档[链接](https://pytorch.org/docs/stable/nn.init.html) ，我们发现`torch.nn.init`提供了以下初始化方法： 1 . `torch.nn.init.uniform_`(tensor, a=0.0, b=1.0) 2 . `torch.nn.init.normal_`(tensor, mean=0.0, std=1.0) 3 . `torch.nn.init.constant_`(tensor, val) 4 . `torch.nn.init.ones_`(tensor) 5 . `torch.nn.init.zeros_`(tensor) 6 . `torch.nn.init.eye_`(tensor) 7 . `torch.nn.init.dirac_`(tensor, groups=1) 8 . `torch.nn.init.xavier_uniform_`(tensor, gain=1.0) 9 . `torch.nn.init.xavier_normal_`(tensor, gain=1.0) 10 . `torch.nn.init.kaiming_uniform_`(tensor, a=0, mode='fan__in', nonlinearity='leaky_relu') 11 . `torch.nn.init.kaiming_normal_`(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu') 12 . `torch.nn.init.orthogonal_`(tensor, gain=1) 13 . `torch.nn.init.sparse_`(tensor, sparsity, std=0.01) 14 . `torch.nn.init.calculate_gain`(nonlinearity, param=None) 关于计算增益如下表：\n",
    "\n",
    "| nonlinearity    | gain                 |\n",
    "| --------------- | -------------------- |\n",
    "| Linear/Identity | 1                    |\n",
    "| Conv{1,2,3}D    | 1                    |\n",
    "| Sigmod          | 1                    |\n",
    "| Tanh            | 5/3                  |\n",
    "| ReLU            | sqrt(2)              |\n",
    "| Leaky Relu      | sqrt(2/1+neg_slop^2) |\n",
    "\n",
    "我们可以发现这些函数除了`calculate_gain`，所有函数的后缀都带有下划线，意味着这些函数将会直接原地更改输入张量的值。\n",
    "\n",
    "#### torch.nn.init使用\n",
    "\n",
    "我们通常会根据实际模型来使用`torch.nn.init`进行初始化，通常使用`isinstance`来进行判断模块（回顾3.4模型构建）属于什么类型。\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = nn.Conv2d(1,3,3)\n",
    "linear = nn.Linear(10,1)\n",
    "\n",
    "isinstance(conv,nn.Conv2d)\n",
    "isinstance(linear,nn.Conv2d)\n",
    "True\n",
    "False\n",
    "```\n",
    "\n",
    "对于不同的类型层，我们就可以设置不同的权值初始化的方法。\n",
    "\n",
    "```\n",
    "# 查看随机初始化的conv参数\n",
    "conv.weight.data\n",
    "# 查看linear的参数\n",
    "linear.weight.data\n",
    "tensor([[[[ 0.1174,  0.1071,  0.2977],\n",
    "          [-0.2634, -0.0583, -0.2465],\n",
    "          [ 0.1726, -0.0452, -0.2354]]],\n",
    "        [[[ 0.1382,  0.1853, -0.1515],\n",
    "          [ 0.0561,  0.2798, -0.2488],\n",
    "          [-0.1288,  0.0031,  0.2826]]],\n",
    "        [[[ 0.2655,  0.2566, -0.1276],\n",
    "          [ 0.1905, -0.1308,  0.2933],\n",
    "          [ 0.0557, -0.1880,  0.0669]]]])\n",
    "\n",
    "tensor([[-0.0089,  0.1186,  0.1213, -0.2569,  0.1381,  0.3125,  0.1118, -0.0063, -0.2330,  0.1956]])\n",
    "# 对conv进行kaiming初始化\n",
    "torch.nn.init.kaiming_normal_(conv.weight.data)\n",
    "conv.weight.data\n",
    "# 对linear进行常数初始化\n",
    "torch.nn.init.constant_(linear.weight.data,0.3)\n",
    "linear.weight.data\n",
    "tensor([[[[ 0.3249, -0.0500,  0.6703],\n",
    "          [-0.3561,  0.0946,  0.4380],\n",
    "          [-0.9426,  0.9116,  0.4374]]],\n",
    "        [[[ 0.6727,  0.9885,  0.1635],\n",
    "          [ 0.7218, -1.2841, -0.2970],\n",
    "          [-0.9128, -0.1134, -0.3846]]],\n",
    "        [[[ 0.2018,  0.4668, -0.0937],\n",
    "          [-0.2701, -0.3073,  0.6686],\n",
    "          [-0.3269, -0.0094,  0.3246]]]])\n",
    "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,0.3000]])\n",
    "```\n",
    "\n",
    "#### 初始化函数的封装\n",
    "\n",
    "人们常常将各种初始化方法定义为一个`initialize_weights()`的函数并在模型初始后进行使用。\n",
    "\n",
    "```\n",
    "def initialize_weights(self):\n",
    "\tfor m in self.modules():\n",
    "\t\t# 判断是否属于Conv2d\n",
    "\t\tif isinstance(m, nn.Conv2d):\n",
    "\t\t\ttorch.nn.init.xavier_normal_(m.weight.data)\n",
    "\t\t\t# 判断是否有偏置\n",
    "\t\t\tif m.bias is not None:\n",
    "\t\t\t\ttorch.nn.init.constant_(m.bias.data,0.3)\n",
    "\t\telif isinstance(m, nn.Linear):\n",
    "\t\t\ttorch.nn.init.normal_(m.weight.data, 0.1)\n",
    "\t\t\tif m.bias is not None:\n",
    "\t\t\t\ttorch.nn.init.zeros_(m.bias.data)\n",
    "\t\telif isinstance(m, nn.BatchNorm2d):\n",
    "\t\t\tm.weight.data.fill_(1) \t\t \n",
    "\t\t\tm.bias.data.zeros_()\t\n",
    "```\n",
    "\n",
    "这段代码流程是遍历当前模型的每一层，然后判断各层属于什么类型，然后根据不同类型层，设定不同的权值初始化方法。我们可以通过下面的例程进行一个简短的演示：\n",
    "\n",
    "```\n",
    "# 模型的定义\n",
    "class MLP(nn.Module):\n",
    "  # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "  def __init__(self, **kwargs):\n",
    "    # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "    super(MLP, self).__init__(**kwargs)\n",
    "    self.hidden = nn.Conv2d(1,1,3)\n",
    "    self.act = nn.ReLU()\n",
    "    self.output = nn.Linear(10,1)\n",
    "    \n",
    "   # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "  def forward(self, x):\n",
    "    o = self.act(self.hidden(x))\n",
    "    return self.output(o)\n",
    "\n",
    "mlp = MLP()\n",
    "print(list(mlp.parameters()))\n",
    "print(\"-------初始化-------\")\n",
    "\n",
    "initialize_weights(mlp)\n",
    "print(list(mlp.parameters()))\n",
    "[Parameter containing:\n",
    "tensor([[[[ 0.2103, -0.1679,  0.1757],\n",
    "          [-0.0647, -0.0136, -0.0410],\n",
    "          [ 0.1371, -0.1738, -0.0850]]]], requires_grad=True), Parameter containing:\n",
    "tensor([0.2507], requires_grad=True), Parameter containing:\n",
    "tensor([[ 0.2790, -0.1247,  0.2762,  0.1149, -0.2121, -0.3022, -0.1859,  0.2983,\n",
    "         -0.0757, -0.2868]], requires_grad=True), Parameter containing:\n",
    "tensor([-0.0905], requires_grad=True)]\n",
    "\"-------初始化-------\"\n",
    "[Parameter containing:\n",
    " tensor([[[[-0.3196, -0.0204, -0.5784],\n",
    "           [ 0.2660,  0.2242, -0.4198],\n",
    "           [-0.0952,  0.6033, -0.8108]]]], requires_grad=True),\n",
    " Parameter containing:\n",
    " tensor([0.3000], requires_grad=True),\n",
    " Parameter containing:\n",
    " tensor([[ 0.7542,  0.5796,  2.2963, -0.1814, -0.9627,  1.9044,  0.4763,  1.2077,\n",
    "           0.8583,  1.9494]], requires_grad=True),\n",
    " Parameter containing:\n",
    " tensor([0.], requires_grad=True)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四章：PyTorch基础实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础实战——FashionMNIST时装分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过前面三章内容的学习，我们完成了以下的内容：\n",
    "\n",
    "- 对PyTorch有了初步的认识\n",
    "- 学会了如何安装PyTorch以及对应的编程环境\n",
    "- 学习了PyTorch最核心的理论基础（张量&自动求导）\n",
    "- 梳理了利用PyTorch完成深度学习的主要步骤和对应实现方式\n",
    "\n",
    "现在，我们通过一个基础实战案例，将第一部分所涉及的PyTorch入门知识串起来，便于大家加深理解。同时为后续的进阶学习打好基础。\n",
    "\n",
    "我们这里的任务是对10个类别的“时装”图像进行分类，使用FashionMNIST数据集（https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion ）。上图给出了FashionMNIST中数据的若干样例图，其中每个小图对应一个样本。\n",
    "FashionMNIST数据集中包含已经预先划分好的训练集和测试集，其中训练集共60,000张图像，测试集共10,000张图像。每张图像均为单通道黑白图像，大小为28*28pixel，分属10个类别。\n",
    "\n",
    "下面让我们一起将第三章各部分内容逐步实现，来跑完整个深度学习流程。\n",
    "\n",
    "**首先导入必要的包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置训练环境和超参数\n",
    "# 配置GPU，这里有两种方式\n",
    "## 方案一：使用os.environ\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\n",
    "batch_size = 256\n",
    "num_workers = 0   # 对于Windows用户，这里应设置为0，否则会出现多线程错误\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据读入和加载**\n",
    "这里同时展示两种方式:\n",
    "\n",
    "- 下载并使用PyTorch提供的内置数据集\n",
    "- 从网站下载以csv格式存储的数据，读入并转成预期的格式\n",
    "  第一种数据读入方式只适用于常见的数据集，如MNIST，CIFAR10等，PyTorch官方提供了数据下载。这种方式往往适用于快速测试方法（比如测试下某个idea在MNIST数据集上是否有效）\n",
    "  第二种数据读入方式需要自己构建Dataset，这对于PyTorch应用于自己的工作中十分重要\n",
    "\n",
    "同时，还需要对数据进行必要的变换，比如说需要将图片统一为一致的大小，以便后续能够输入网络训练；需要将数据格式转为Tensor类，等等。\n",
    "\n",
    "这些变换可以很方便地借助torchvision包来完成，这是PyTorch官方用于图像处理的工具库，上面提到的使用内置数据集的方式也要用到。PyTorch的一大方便之处就在于它是一整套“生态”，有着官方和第三方各个领域的支持。这些内容我们会在后续课程中详细介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),   # 这一步取决于后续的数据读取方式，如果使用内置数据集则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式一：使用torchvision自带数据集，下载可能需要一段时间\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n",
    "test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式二：读入csv格式的数据，自行构建Dataset类\n",
    "# csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在构建训练和测试数据集完成后，需要定义DataLoader类，以便在训练和测试时加载数据\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a798e93e48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAARdElEQVR4nO3db2xWdZYH8O+x/NP+obRCqUAYGI0GNTKkQSJm42ay6KAJ8sbAiwmbmO2YzCQzybxY476AN5uYdWdm54WZpLOSYTazkjGMkRdkhUUSQ6KEP0EK6CoWcID+AUWhUgqFsy96NR3tPac89z7PvfZ8P0nT9p7n1+dw6/E+fc79/X6iqiCiye+2ohMgotpgsRMFwWInCoLFThQEi50oiCm1fDIR4Vv/45gyxf41tLS0mPErV66kxgYHByvKqRaamprMuHdeLl68aMajdppUVcY7nqnYReQJAL8FUAfgP1X1xSw/L6rm5mYzvn79ejN+8ODB1NjevXsrSakmVq5caca987Jt2zYzfu3atVtNaVKr+GW8iNQBeBnAjwAsAbBeRJbklRgR5SvL3+zLAZxQ1R5VvQZgK4A1+aRFRHnLUuzzAPx1zPdnkmN/Q0Q6ReSAiBzI8FxElFHV36BT1S4AXQDfoCMqUpYr+1kAC8Z8Pz85RkQllKXY9wO4R0QWicg0AOsAbM8nLSLKm2TpRYrIagD/gdHW22ZV/Vfn8YW9jBcZt/X4tSzn4eGHHzbjTz31lBlvb28340NDQxU//+nTp82xXi/7888/zzS+sbExNXb77bebY7u7u814a2urGT9y5EhqbOfOnebYY8eOmfEyq0qfXVV3ANiR5WcQUW3wdlmiIFjsREGw2ImCYLETBcFiJwqCxU4URKY++y0/2Xf4dlmrV7527VpzrNfrbmhoMOPevG1rXvicOXPMsd7vf+bMmWbcmy8/PDycGvvggw/Msd48/vPnz5txK/d7773XHLt582YzvmfPHjNepLQ+O6/sREGw2ImCYLETBcFiJwqCxU4UBIudKIiaLiX9XdbR0ZEa27dvnznWm8r56aefmvFly5aZ8XPnzqXG6uvrzbFWawwAZs+ebcavX79uxq224aJFi8yxly5dMuN1dXVm/MKFC6kxr2X4yCOPmPEyt97S8MpOFASLnSgIFjtRECx2oiBY7ERBsNiJgmCxEwXBPnvi/vvvN+MjIyOpsZs3b1Y8FvB7vt4UWcvHH39sxlesWGHGvSWVFyxYYMataajeefHiN27cMOMzZsww41nG3nHHHWbc2ka7KLyyEwXBYicKgsVOFASLnSgIFjtRECx2oiBY7ERBsM+euO+++8y4NW/bm6/uzRmfOnWqGff67HPnzk2NnTx50hw7a9YsM37XXXeZ8XfeeceM9/X1pca8XrU3V95jzeX37o3wnvvuu+8249Z20UXJVOwicgrAZQA3AIyoavoKD0RUqDyu7H+vqulLghBRKfBvdqIgsha7AtgpIgdFpHO8B4hIp4gcEJEDGZ+LiDLI+jL+UVU9KyJzAOwSkQ9U9e2xD1DVLgBdwHd7rzei77pMV3ZVPZt8HgDwOoDleSRFRPmruNhFpF5EGr/6GsAqAEfzSoyI8pXlZXwbgNdF5Kuf89+q+j+5ZFUAr5989erV1Jg399mbr+71fG+7zf5/8sDAQGps+vTp5livT75w4UIz/sknn5jxxsbG1Jj378p6Xqzx3r0N3nMvWbLEjE+qPruq9gB4KMdciKiK2HojCoLFThQEi50oCBY7URAsdqIgOMU10dTUZMatJZFbW1vNsdbWwYC/7PCUKfavadq0aakxr8XkteZOnDhhxhsaGsy4ZWhoqOKxgN96s3hTe71pxQ8++KAZ37p16y3nVG28shMFwWInCoLFThQEi50oCBY7URAsdqIgWOxEQYTps3u9cK9f3N/fX/HPtsYCdg8fsKeJAvZ0TG9JZG8qp7dMtrdtshXPOoXV69Nbv5fZs2ebY9977z0z/tBD9oTPMm7pzCs7URAsdqIgWOxEQbDYiYJgsRMFwWInCoLFThREmD67N//Y64ta877r6urMsc3NzWb8+PHjZtzLzeL1srP2urM8v/ezvXn8165dqygnwJ/nb233DPi/8yeffNKMv/baa2a8GnhlJwqCxU4UBIudKAgWO1EQLHaiIFjsREGw2ImCCNNn99ZHb29vN+N9fX2psZaWFnOsNyd8z549ZtzrCVtzxrP2qr0+vLVmPQCMjIykxry59l7uyXbhqayttL11470tvL259MPDw2a8CO6VXUQ2i8iAiBwdc6xFRHaJyEfJZ/vMEVHhJvIy/g8AnvjGsecB7FbVewDsTr4nohJzi11V3wbw2TcOrwGwJfl6C4Cn802LiPJW6d/sbaram3zdB6At7YEi0gmgs8LnIaKcZH6DTlVVRNSIdwHoAgDrcURUXZW23vpFpB0Aks8D+aVERNVQabFvB7Ah+XoDgDfySYeIqsV9GS8irwJ4DMCdInIGwEYALwL4s4g8C+A0gGeqmWQe3nzzTTN+8uRJM75mzZrU2OLFi82xPT09Ztzrw2edk56Fara/vKx7ALyf7c1399ast8Y3NTWZY7u7u8349u3bzXgZucWuqutTQj/MORciqiLeLksUBIudKAgWO1EQLHaiIFjsREGEmeLq+fDDD834Sy+9lBo7deqUOXb//v1mfMWKFWbcY7WwqtmWmwhvGqqlmstcr1u3zowPDEy++8R4ZScKgsVOFASLnSgIFjtRECx2oiBY7ERBsNiJgmCfPQfe9rvWksaAv4x1b2+vGc+yLbI3zTTr9FprKelqbxdtLcGdtY/u3T+QdWpwNfDKThQEi50oCBY7URAsdqIgWOxEQbDYiYJgsRMFwT77BFl9Va+nOnfu3EzP7W3ZbG0f7PWqs8w3B/xtla2ti71/V11dnRm3evgAUF9fnxrztpr2trIuYx/dwys7URAsdqIgWOxEQbDYiYJgsRMFwWInCoLFThQE++w14PV0y8zr03tbH/f19aXGpk+fnum5vS2brfny3jbZXp99Us5nF5HNIjIgIkfHHNskImdF5HDysbq6aRJRVhN5Gf8HAE+Mc/w3qro0+diRb1pElDe32FX1bQCf1SAXIqqiLG/Q/UxEjiQv82elPUhEOkXkgIgcyPBcRJRRpcX+OwDfB7AUQC+AX6U9UFW7VLVDVTsqfC4iykFFxa6q/ap6Q1VvAvg9gOX5pkVEeauo2EVk7NrHawEcTXssEZWD22cXkVcBPAbgThE5A2AjgMdEZCkABXAKwE+ql2I5ZOmben32rOunV7On680pb2xsrNpzZ103/sqVK6mx1tZWc+wXX3xhxr15/NevXzfjRXCLXVXXj3P4lSrkQkRVxNtliYJgsRMFwWInCoLFThQEi50oCE5xrYF58+aZ8axTYK32mDeNdHBw0Ix7uXk/31ou2mvreXFvmqnV0vSW9+7p6THj3jLWZcQrO1EQLHaiIFjsREGw2ImCYLETBcFiJwqCxU4UBPvsNeBN1fSmS2YZ7/Wis27Z3NLSYsatXrm3ZbN3Xrx7AKztor2lpD1lXCrawys7URAsdqIgWOxEQbDYiYJgsRMFwWInCoLFThQE++w14PWTvT66t9S01cv2etVebt7Wxd6WzVevXk2NNTc3m2Oz9uGt5Zy9+wM8k3LLZiKaHFjsREGw2ImCYLETBcFiJwqCxU4UBIudKAj22Wtg5syZZtxbg9zrw1t9dq9H7/Wqb9y4Yca9rY9nzJiRGvPWhffWpPfOi3Ves87j957bO29FcK/sIrJARPaIyHEROSYiP0+Ot4jILhH5KPk8q/rpElGlJvIyfgTAL1V1CYAVAH4qIksAPA9gt6reA2B38j0RlZRb7Kraq6qHkq8vA3gfwDwAawBsSR62BcDTVcqRiHJwS3+zi8j3APwAwD4Abaram4T6ALSljOkE0JkhRyLKwYTfjReRBgDbAPxCVS+NjenoXf/j3vmvql2q2qGqHZkyJaJMJlTsIjIVo4X+J1X9S3K4X0Tak3g7gIHqpEhEeXBfxstoj+IVAO+r6q/HhLYD2ADgxeTzG1XJsEaqOWXRayF500it9hXgt9csWXPz2opWi8qbwurl5v27reWis05BzXLOizKRv9lXAvgxgG4ROZwcewGjRf5nEXkWwGkAz1QlQyLKhVvsqroXQNpl74f5pkNE1cLbZYmCYLETBcFiJwqCxU4UBIudKAhOcU0UufRvY2NjpvHWksleL3twcNCMe+cly5bN9fX15ljv/gJvy2ZrmWtvrKeMS0V7eGUnCoLFThQEi50oCBY7URAsdqIgWOxEQbDYiYJgn70ELl26ZMaHh4fN+Jdffpka85Y07u/vN+NeP7mhocGMW1s2e//uhQsXmnHP0NBQasy7v8DDLZuJqLRY7ERBsNiJgmCxEwXBYicKgsVOFASLnSgI9tlrwFv/fOXKlWb83LlzZtzqVzc3N5tjvdy8Xre3bvzjjz+eGpszZ4451pqPDvi9cmu8d3+Bx9vq2lpjoCi8shMFwWInCoLFThQEi50oCBY7URAsdqIgWOxEQUxkf/YFAP4IoA2AAuhS1d+KyCYA/wTgfPLQF1R1R7USLZo1f9mbu/zyyy+b8WXLlpnxRYsWmXGr3+z12a258IC9xzng95OtXrc3135gYMCMP/DAA2b8woULqbF3333XHOsZGRnJNL4IE7mpZgTAL1X1kIg0AjgoIruS2G9U9d+rlx4R5WUi+7P3AuhNvr4sIu8DmFftxIgoX7f0N7uIfA/ADwDsSw79TESOiMhmEZmVMqZTRA6IyIFsqRJRFhMudhFpALANwC9U9RKA3wH4PoClGL3y/2q8carapaodqtqRPV0iqtSEil1EpmK00P+kqn8BAFXtV9UbqnoTwO8BLK9emkSUlVvsMvo29CsA3lfVX4853j7mYWsBHM0/PSLKy0TejV8J4McAukXkcHLsBQDrRWQpRttxpwD8pAr5lUY1lwZ+7rnnzPimTZvM+PLl6S+qvKWevWmi3hRYb8tmawpsa2urOdZr6x06dMiMb9y40YxHM5F34/cCGK/JPGl76kSTEe+gIwqCxU4UBIudKAgWO1EQLHaiIFjsREFILbeWFZHy7WM7CVi97FWrVplj58+fb8YXL15sxtva2sz4W2+9lRq7fPmyOXbHDru7e/HiRTMelaqOOx+bV3aiIFjsREGw2ImCYLETBcFiJwqCxU4UBIudKIha99nPAzg95tCdANLX+y1WWXMra14Ac6tUnrktVNXZ4wVqWuzfenKRA2Vdm66suZU1L4C5VapWufFlPFEQLHaiIIou9q6Cn99S1tzKmhfA3CpVk9wK/ZudiGqn6Cs7EdUIi50oiEKKXUSeEJH/E5ETIvJ8ETmkEZFTItItIoeL3p8u2UNvQESOjjnWIiK7ROSj5PO4e+wVlNsmETmbnLvDIrK6oNwWiMgeETkuIsdE5OfJ8ULPnZFXTc5bzf9mF5E6AB8C+AcAZwDsB7BeVY/XNJEUInIKQIeqFn4Dhoj8HYBBAH9U1QeSY/8G4DNVfTH5H+UsVf3nkuS2CcBg0dt4J7sVtY/dZhzA0wD+EQWeOyOvZ1CD81bElX05gBOq2qOq1wBsBbCmgDxKT1XfBvDZNw6vAbAl+XoLRv9jqbmU3EpBVXtV9VDy9WUAX20zXui5M/KqiSKKfR6Av475/gzKtd+7AtgpIgdFpLPoZMbRpqq9ydd9AOx1oWrP3ca7lr6xzXhpzl0l259nxTfovu1RVV0G4EcAfpq8XC0lHf0brEy90wlt410r42wz/rUiz12l259nVUSxnwWwYMz385NjpaCqZ5PPAwBeR/m2ou7/agfd5PNAwfl8rUzbeI+3zThKcO6K3P68iGLfD+AeEVkkItMArAOwvYA8vkVE6pM3TiAi9QBWoXxbUW8HsCH5egOANwrM5W+UZRvvtG3GUfC5K3z7c1Wt+QeA1Rh9R/5jAP9SRA4peS0G8F7ycazo3AC8itGXddcx+t7GswBaAewG8BGA/wXQUqLc/gtAN4AjGC2s9oJyexSjL9GPADicfKwu+twZedXkvPF2WaIg+AYdURAsdqIgWOxEQbDYiYJgsRMFwWInCoLFThTE/wPuQ7LTcmxaxgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读入后，我们可以做一些数据可视化操作，主要是验证我们读入的数据是否正确\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型设计\n",
    "由于任务较为简单，这里我们手搭一个CNN，而不考虑当下各种模型的复杂结构，模型构建完成后，将模型放到GPU上用于训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        # x = nn.functional.normalize(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda()   # 多卡训练时的写法，之后的课程中会进一步讲解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设定损失函数\n",
    "使用torch.nn模块自带的CrossEntropy损失\n",
    "PyTorch会自动把整数型的label转为one-hot型，用于计算CE loss\n",
    "这里需要确保label是从0开始的，同时模型不加softmax层（使用logits计算）,这也说明了PyTorch训练中各个部分不是独立的，需要通盘考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "This criterion computes the cross entropy loss between input and target.\n",
      "\n",
      "It is useful when training a classification problem with `C` classes.\n",
      "If provided, the optional argument :attr:`weight` should be a 1D `Tensor`\n",
      "assigning weight to each of the classes.\n",
      "This is particularly useful when you have an unbalanced training set.\n",
      "\n",
      "The `input` is expected to contain raw, unnormalized scores for each class.\n",
      "`input` has to be a Tensor of size either :math:`(minibatch, C)` or\n",
      ":math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` for the\n",
      "`K`-dimensional case. The latter is useful for higher dimension inputs, such\n",
      "as computing cross entropy loss per-pixel for 2D images.\n",
      "\n",
      "The `target` that this criterion expects should contain either:\n",
      "\n",
      "- Class indices in the range :math:`[0, C-1]` where :math:`C` is the number of classes; if\n",
      "  `ignore_index` is specified, this loss also accepts this class index (this index\n",
      "  may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`\n",
      "  set to ``'none'``) loss for this case can be described as:\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "      l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
      "      \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
      "\n",
      "  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = \\begin{cases}\n",
      "          \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n",
      "           \\text{if reduction} = \\text{`mean';}\\\\\n",
      "            \\sum_{n=1}^N l_n,  &\n",
      "            \\text{if reduction} = \\text{`sum'.}\n",
      "        \\end{cases}\n",
      "\n",
      "  Note that this case is equivalent to the combination of :class:`~torch.nn.LogSoftmax` and\n",
      "  :class:`~torch.nn.NLLLoss`.\n",
      "\n",
      "- Probabilities for each class; useful when labels beyond a single class per minibatch item\n",
      "  are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n",
      "  :attr:`reduction` set to ``'none'``) loss for this case can be described as:\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "      l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\exp(\\sum_{i=1}^C x_{n,i})} y_{n,c}\n",
      "\n",
      "  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = \\begin{cases}\n",
      "          \\frac{\\sum_{n=1}^N l_n}{N}, &\n",
      "           \\text{if reduction} = \\text{`mean';}\\\\\n",
      "            \\sum_{n=1}^N l_n,  &\n",
      "            \\text{if reduction} = \\text{`sum'.}\n",
      "        \\end{cases}\n",
      "\n",
      ".. note::\n",
      "    The performance of this criterion is generally better when `target` contains class\n",
      "    indices, as this allows for optimized computation. Consider providing `target` as\n",
      "    class probabilities only when a single class label per minibatch item is too restrictive.\n",
      "\n",
      "Args:\n",
      "    weight (Tensor, optional): a manual rescaling weight given to each class.\n",
      "        If given, has to be a Tensor of size `C`\n",
      "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "        the losses are averaged over each loss element in the batch. Note that for\n",
      "        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "        when :attr:`reduce` is ``False``. Default: ``True``\n",
      "    ignore_index (int, optional): Specifies a target value that is ignored\n",
      "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "        ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "        :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "        losses are averaged or summed over observations for each minibatch depending\n",
      "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
      "        be applied, ``'mean'``: the weighted mean of the output is taken,\n",
      "        ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "        and :attr:`reduce` are in the process of being deprecated, and in\n",
      "        the meantime, specifying either of those two args will override\n",
      "        :attr:`reduction`. Default: ``'mean'``\n",
      "    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "        become a mixture of the original ground truth and a uniform distribution as described in\n",
      "        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(N, C)` where `C = number of classes`, or\n",
      "      :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "      in the case of `K`-dimensional loss.\n",
      "    - Target: If containing class indices, shape :math:`(N)` where each value is\n",
      "      :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "      :math:`K \\geq 1` in the case of K-dimensional loss. If containing class probabilities,\n",
      "      same shape as the input.\n",
      "    - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or\n",
      "      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of K-dimensional loss.\n",
      "      Otherwise, scalar.\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> # Example of target with class indices\n",
      "    >>> loss = nn.CrossEntropyLoss()\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
      "    >>> output = loss(input, target)\n",
      "    >>> output.backward()\n",
      "    >>>\n",
      "    >>> # Example of target with class probabilities\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "    >>> output = loss(input, target)\n",
      "    >>> output.backward()\n",
      "\u001b[1;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\programdata\\anaconda3\\envs\\torch_py37\\lib\\site-packages\\torch\\nn\\modules\\loss.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "# 这里方便看一下weighting等策略\n",
    "?nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设定优化器\n",
    "这里我们使用Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练和测试（验证）\n",
    "各自封装成函数，方便后续调用\n",
    "关注两者的主要区别：\n",
    "\n",
    "- 模型状态设置\n",
    "\n",
    "- 是否需要初始化优化器\n",
    "\n",
    "- 是否需要将loss传回到网络\n",
    "\n",
    "- 是否需要每步更新optimizer\n",
    "\n",
    "此外，对于测试或验证过程，可以计算分类准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):       \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, 1)\n",
    "            gt_labels.append(label.cpu().data.numpy())\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    val_loss = val_loss/len(test_loader.dataset)\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.626581\n",
      "Epoch: 1 \tValidation Loss: 0.390644, Accuracy: 0.859900\n",
      "Epoch: 2 \tTraining Loss: 0.398027\n",
      "Epoch: 2 \tValidation Loss: 0.330118, Accuracy: 0.881300\n",
      "Epoch: 3 \tTraining Loss: 0.348101\n",
      "Epoch: 3 \tValidation Loss: 0.298876, Accuracy: 0.892600\n",
      "Epoch: 4 \tTraining Loss: 0.318027\n",
      "Epoch: 4 \tValidation Loss: 0.282844, Accuracy: 0.899000\n",
      "Epoch: 5 \tTraining Loss: 0.300405\n",
      "Epoch: 5 \tValidation Loss: 0.262062, Accuracy: 0.902400\n",
      "Epoch: 6 \tTraining Loss: 0.284113\n",
      "Epoch: 6 \tValidation Loss: 0.252238, Accuracy: 0.906700\n",
      "Epoch: 7 \tTraining Loss: 0.267998\n",
      "Epoch: 7 \tValidation Loss: 0.242292, Accuracy: 0.908900\n",
      "Epoch: 8 \tTraining Loss: 0.257782\n",
      "Epoch: 8 \tValidation Loss: 0.233853, Accuracy: 0.913800\n",
      "Epoch: 9 \tTraining Loss: 0.248029\n",
      "Epoch: 9 \tValidation Loss: 0.233900, Accuracy: 0.914700\n",
      "Epoch: 10 \tTraining Loss: 0.239142\n",
      "Epoch: 10 \tValidation Loss: 0.229731, Accuracy: 0.915500\n",
      "Epoch: 11 \tTraining Loss: 0.229392\n",
      "Epoch: 11 \tValidation Loss: 0.237546, Accuracy: 0.908200\n",
      "Epoch: 12 \tTraining Loss: 0.222377\n",
      "Epoch: 12 \tValidation Loss: 0.219004, Accuracy: 0.917500\n",
      "Epoch: 13 \tTraining Loss: 0.214063\n",
      "Epoch: 13 \tValidation Loss: 0.220920, Accuracy: 0.914800\n",
      "Epoch: 14 \tTraining Loss: 0.208833\n",
      "Epoch: 14 \tValidation Loss: 0.216172, Accuracy: 0.918900\n",
      "Epoch: 15 \tTraining Loss: 0.201596\n",
      "Epoch: 15 \tValidation Loss: 0.216080, Accuracy: 0.921500\n",
      "Epoch: 16 \tTraining Loss: 0.195586\n",
      "Epoch: 16 \tValidation Loss: 0.210627, Accuracy: 0.920800\n",
      "Epoch: 17 \tTraining Loss: 0.191152\n",
      "Epoch: 17 \tValidation Loss: 0.221553, Accuracy: 0.919100\n",
      "Epoch: 18 \tTraining Loss: 0.184396\n",
      "Epoch: 18 \tValidation Loss: 0.207905, Accuracy: 0.923900\n",
      "Epoch: 19 \tTraining Loss: 0.177960\n",
      "Epoch: 19 \tValidation Loss: 0.202692, Accuracy: 0.925700\n",
      "Epoch: 20 \tTraining Loss: 0.174407\n",
      "Epoch: 20 \tValidation Loss: 0.202864, Accuracy: 0.925500\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型保存\n",
    "训练完成后，可以使用torch.save保存模型参数或者整个模型，也可以在训练过程中保存模型\n",
    "这部分会在后面的课程中详细介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./FahionModel.pkl\"\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f68a7a19ceb69147e2b1806248225db4b52a6106a01cc4bb6cd26c7074c6480"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch_py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
